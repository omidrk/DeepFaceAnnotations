{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "freeParsingFace.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uicPIKQBr3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/zllrunning/face-parsing.PyTorch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGqj23AVagEV",
        "colab_type": "text"
      },
      "source": [
        "Dont need these anymore\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH5RjbDJam2g",
        "colab_type": "text"
      },
      "source": [
        "Need to Install few things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YhyBCyhak1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorboardX wandb\n",
        "!unzip faceparsing.zip\n",
        "!gdown https://drive.google.com/uc?id=154JgKpzCPW82qINcVieuPH3fZ2e0P812 -O faceparsing/79999_iter.pth\n",
        "\n",
        "#for dataset\n",
        "!git clone https://github.com/nalbert9/Facial-Keypoint-Detection.git\n",
        "\n",
        "#load weight and biases\n",
        "!wandb login c3c8bc8ee408b8d8d1e170586aa0c70bc4542720\n",
        "\n",
        "# Init wandb\n",
        "import wandb\n",
        "wandb.init(project=\"deepannotation\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHSaYcdfb5_d",
        "colab_type": "text"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pF92iRvEkGf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.model_zoo as modelzoo\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import os.path as osp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "#Set cuda Driver \n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda:0' if use_cuda else 'cpu')\n",
        "\n",
        "#Load Writen Libraries\n",
        "\n",
        "##To get Free annotation\n",
        "from faceparsing.model import BiSeNet\n",
        "\n",
        "#My Models\n",
        "from faceparsing.Models import Net\n",
        "from faceparsing.data_load import FacialKeypointsDataset,Normalize,Rescale,RandomCrop,ToTensor\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZHT2kqJb4pG",
        "colab_type": "text"
      },
      "source": [
        "Get Free annotation network Ready for face parsing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZTbLwKECuME",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 19\n",
        "net = BiSeNet(n_classes=n_classes)\n",
        "net.cuda()\n",
        "save_pth = 'faceparsing/79999_iter.pth'\n",
        "net.load_state_dict(torch.load(save_pth))\n",
        "net.eval()\n",
        "\n",
        "#For preparing Image as Input\n",
        "to_tensor = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
        "    ])\n",
        "\n",
        "#Parsing face\n",
        "with torch.no_grad():\n",
        "\n",
        "  img = Image.open('im.jpeg')\n",
        "  image = img.resize((512, 512), Image.BILINEAR)\n",
        "  img = to_tensor(image)\n",
        "  img = torch.unsqueeze(img, 0)\n",
        "  img = img.cuda()\n",
        "  out = net(img)[0]\n",
        "  parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
        "  print(parsing)\n",
        "  # print(np.unique(parsing))\n",
        "\n",
        "def FaceParser(img):\n",
        "  image = img.resize((512, 512), Image.BILINEAR)\n",
        "  img = to_tensor(image)\n",
        "  img = torch.unsqueeze(img, 0)\n",
        "  img = img.cuda()\n",
        "  out = net(img)[0]\n",
        "  parsing = out.squeeze(0).cpu().numpy().argmax(0)\n",
        "  return parsing\n",
        "\n",
        "def GetHaieAnnotationXY(parsing):\n",
        "  #Use Canny edge detector from openCv to find hair edges\n",
        "  hairx,hairy = np.where(parsing==17)\n",
        "  edge = np.zeros((512,512))\n",
        "  edge[hairx,hairy] = 255\n",
        "  edges = cv2.Canny(np.uint8(edge),512,512)\n",
        "  #Convert hair edgesarray to X,Y from many edges point\n",
        "  edgex,edgey = np.where(edges==255)\n",
        "  #Select 68 point randomly as hair annotation\n",
        "  dots = np.zeros((2,68))\n",
        "  for i in range(68):\n",
        "    r = np.random.randint(0,len(edgex))\n",
        "    dots[0,i] = edgex[r]\n",
        "    dots[1,i] = edgey[r]\n",
        "  return dots\n",
        "\n",
        "\n",
        "  # plt.imshow(mask)\n",
        "  #plt.imshow(edges)\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TiH0lh0kcW0",
        "colab_type": "text"
      },
      "source": [
        "First Simple Model Without hyper parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eyHHaNEzMrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Init CNN Model\n",
        "net = Net()\n",
        "net = net.cuda()\n",
        "wandb.watch(net, log=\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpK5sSkpmgSl",
        "colab_type": "text"
      },
      "source": [
        "Intiate Dataset and make Transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQK3jOofE-zv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the data tranform\n",
        "data_transform = transforms.Compose([Rescale(250),\n",
        "                                     RandomCrop(224),\n",
        "                                     Normalize(),\n",
        "                                     ToTensor()])\n",
        "# create the transformed dataset\n",
        "transformed_dataset = FacialKeypointsDataset(csv_file='data/training_frames_keypoints.csv',\n",
        "                                             root_dir='data/training/',\n",
        "                                             transform=data_transform)\n",
        "# load training data in batches\n",
        "batch_size = 10\n",
        "train_loader = DataLoader(transformed_dataset, \n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)\n",
        "# create the test dataset\n",
        "test_dataset = FacialKeypointsDataset(csv_file='data/test_frames_keypoints.csv',\n",
        "                                             root_dir='data/test/',\n",
        "                                             transform=data_transform)\n",
        "# load test data in batches\n",
        "test_loader = DataLoader(test_dataset, \n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIct7vwqnTKO",
        "colab_type": "text"
      },
      "source": [
        "Defining Loss Functions and optimizers. This can be separated later for cleaning perpose to lossClass.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYrUIinBEkzO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "criterion = criterion.cuda(device)\n",
        "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAeZTWUInk4B",
        "colab_type": "text"
      },
      "source": [
        "Defining Train/Test Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5Ct1ycegeNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_net(n_epochs,net):\n",
        "\n",
        "    # prepare the net for training\n",
        "    \n",
        "    # with torch.no_grad():\n",
        "\n",
        "      \n",
        "      net.train()\n",
        "      training_loss = []\n",
        "      for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
        "        \n",
        "          running_loss = 0.0\n",
        "\n",
        "          # train on batches of data, assumes you already have train_loader\n",
        "          for batch_i, data in enumerate(train_loader):\n",
        "            # get the input images and their corresponding labels\n",
        "            images = data['image']\n",
        "            key_pts = data['keypoints']\n",
        "            images2 = images\n",
        "\n",
        "\n",
        "            # flatten pts\n",
        "            key_pts = key_pts.view(key_pts.size(0), -1)\n",
        "\n",
        "            # convert variables to floats for regression loss\n",
        "            key_pts = key_pts.type(torch.FloatTensor)\n",
        "            key_pts = key_pts.to(device)\n",
        "            images = images.type(torch.FloatTensor)\n",
        "            images = images.to(device)\n",
        "\n",
        "            # forward pass to get outputs\n",
        "            output_pts = net(images)\n",
        "\n",
        "            # calculate the loss between predicted and target keypoints\n",
        "            loss = criterion(output_pts, key_pts)\n",
        "\n",
        "            # zero the parameter (weight) gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # backward pass to calculate the weight gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # update the weights\n",
        "            optimizer.step()\n",
        "\n",
        "            #Save All logs to Weights and Biases\n",
        "            wandb.log({\"Images\" : images2})\n",
        "\n",
        "            # print loss statistics\n",
        "            running_loss += loss.item()\n",
        "            if batch_i % 10 == 9:    # print every 10 batches\n",
        "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, running_loss/10))\n",
        "                running_loss = 0.0\n",
        "          training_loss.append(running_loss)\n",
        "\n",
        "      print('Finished Training')\n",
        "      return training_loss\n",
        "\n",
        "\n",
        "def net_sample_output():\n",
        "    \n",
        "    # iterate through the test dataset\n",
        "    for i, sample in enumerate(test_loader):\n",
        "        \n",
        "        # get sample data: images and ground truth keypoints\n",
        "        images = sample['image']\n",
        "        key_pts = sample['keypoints']\n",
        "        key_pts = key_pts.cuda(device)\n",
        "\n",
        "        # convert images to FloatTensors\n",
        "        images = images.type(torch.FloatTensor)\n",
        "        images = images.cuda(device)\n",
        "\n",
        "        # forward pass to get net output\n",
        "        output_pts = net(images)\n",
        "        \n",
        "        # reshape to batch_size x 68 x 2 pts\n",
        "        output_pts = output_pts.view(output_pts.size()[0], 68, -1)\n",
        "        \n",
        "        # break after first image is tested\n",
        "        if i == 0:\n",
        "            return images, output_pts, key_pts\n",
        "\n",
        "        # wandb.log({\"examples\" : images})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_lUzDQVo4kk",
        "colab_type": "text"
      },
      "source": [
        "Train Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsWYc48BhPvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_loss = train_net(n_epochs,net)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOgiXbR4qc9l",
        "colab_type": "text"
      },
      "source": [
        "Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlwaDhXiC5Tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_all_keypoints(image, predicted_key_pts, gt_pts=None):\n",
        "    \"\"\"Show image with predicted keypoints\"\"\"\n",
        "    fig=plt.figure(figsize=(9, 8), dpi= 80, facecolor='w', edgecolor='k')    \n",
        "    # image is grayscale\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.scatter(predicted_key_pts[:, 0], predicted_key_pts[:, 1], s=20, marker='.', c='m')\n",
        "    # plot ground truth points as green pts\n",
        "    if gt_pts is not None:\n",
        "        plt.scatter(gt_pts[:, 0], gt_pts[:, 1], s=20, marker='.', c='g')\n",
        "\n",
        "\n",
        "\n",
        "# visualize the output\n",
        "# by default this shows a batch of 10 images\n",
        "def visualize_output(test_images, test_outputs, gt_pts=None, batch_size=10):\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        plt.figure(figsize=(20,10))\n",
        "        ax = plt.subplot(1, batch_size, i+1)\n",
        "\n",
        "        # un-transform the image data\n",
        "        image = test_images[i].data   # get the image from it's Variable wrapper\n",
        "        image = image.numpy()   # convert to numpy array from a Tensor\n",
        "        image = np.transpose(image, (1, 2, 0))   # transpose to go from torch to numpy image\n",
        "\n",
        "        # un-transform the predicted key_pts data\n",
        "        predicted_key_pts = test_outputs[i].data\n",
        "        predicted_key_pts = predicted_key_pts.numpy()\n",
        "        # undo normalization of keypoints  \n",
        "        predicted_key_pts = predicted_key_pts*50.0+100\n",
        "        \n",
        "        # plot ground truth points for comparison, if they exist\n",
        "        ground_truth_pts = None\n",
        "        if gt_pts is not None:\n",
        "            ground_truth_pts = gt_pts[i]         \n",
        "            ground_truth_pts = ground_truth_pts*50.0+100\n",
        "        \n",
        "        # call show_all_keypoints\n",
        "        show_all_keypoints(np.squeeze(image), predicted_key_pts, ground_truth_pts)\n",
        "            \n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzNS5QTIqsx6",
        "colab_type": "text"
      },
      "source": [
        "Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLTqdvzXEzao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# returns: test images, test predicted keypoints, test ground truth keypoints\n",
        "test_images, test_outputs, gt_pts = net_sample_output()\n",
        "# print out the dimensions of the data to see if they make sense\n",
        "print(test_images.data.size())\n",
        "print(test_outputs.data.size())\n",
        "print(gt_pts.size())\n",
        "    \n",
        "visualize_output(test_images.cpu(), test_outputs.cpu(), gt_pts.cpu())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax6LSQSAFQwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foBwU5pfF7jh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUIiYmHmF87k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySb4GGicH6zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKkPecupkuxI",
        "colab_type": "text"
      },
      "source": [
        "#################################################\n",
        "# Start Real code\n",
        "Building resNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-yXNll1KK0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjADFf9AKMPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5SzoL73Kr9X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMBT2dm6ri2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDc3ReaPnDwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFPGTcndr6Gk",
        "colab_type": "text"
      },
      "source": [
        "Load data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3535z0uraUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGvH1GHu1t-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUc-mxE7sB4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I98K79MRsCm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A2XbOT6uSqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdejPJ-vu9HQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QpY9fD4x2uY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDvsGLXix_0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIWMBtYtyAow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQBVUfye5yX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKbymSkXAjPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8YPSEI8_KsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25FFzYnV_T6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}